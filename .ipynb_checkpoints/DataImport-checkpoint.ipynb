{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"Sample Data\" #Absolute path for data.\n",
    "numSamples = 100 \n",
    "numFeatures = 2995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_filter(a):\n",
    "    b = np.zeros([numFeatures, 1], float)\n",
    "    print(\"Start:\")\n",
    "    for i in range(len(a)):\n",
    "        lowend = 0\n",
    "        if i<50:\n",
    "            lowend = i  # If there are fewer than 50 bins behind current windows, only go back to index 0.\n",
    "        if i>=50:\n",
    "            lowend = 50  # Else, go back 50 indices.\n",
    "        print(len(a[i-lowend:i+50]))\n",
    "        comp = np.less(a[i], a[i-lowend:(i+50)])  # Compare current value to values for all bins in 100Da range\n",
    "        # print(comp)\n",
    "        if np.sum(comp)<7:  # If value is among top 6 in 100Da range, add it to final array b.\n",
    "            b[i] = a[i]\n",
    "        #if np.sum(comp)>93:\n",
    "            # print(str(i) + \": \" + str(np.sum(comp)))\n",
    "\n",
    "    # Comparison prints of unfiltered and filtered arrays.\n",
    "    # print(a.size)\n",
    "    # print(a.shape)\n",
    "    # print(np.amax(a))\n",
    "    print(np.count_nonzero(a))\n",
    "    # print(b.size)\n",
    "    # print(b.shape)\n",
    "    # print(np.amax(b))\n",
    "    print(np.count_nonzero(b))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = np.zeros([numFeatures, 0], float)\n",
    "    for file in os.listdir(datapath):\n",
    "        if file.endswith(\".txt\"):\n",
    "            print(file)\n",
    "            min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "            filepath = os.path.join(datapath, file)\n",
    "            temp = np.loadtxt(filepath, np.float64, usecols = 2) #U ses only the 3rd column, where intensities are stored.\n",
    "            temp = temp.reshape(-1, 1)\n",
    "            print(np.amax(temp))\n",
    "            # temp = rolling_window_filter(temp)\n",
    "            temp = min_max_scaler.fit_transform(temp)\n",
    "            # temp = rolling_window_filter(temp)\n",
    "            data = np.concatenate([data, temp], axis=1)\n",
    "\n",
    "    print(\"Done\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin_values():\n",
    "    for file in os.listdir(datapath):\n",
    "        if file.endswith(\".txt\"):\n",
    "            filepath = os.path.join(datapath, file)\n",
    "            temp = np.loadtxt(filepath, np.float64, usecols=0)  # Grabs only the lower bound value for each bin\n",
    "            temp = temp.reshape(-1, 1)\n",
    "            temp = temp + 0.5  # Round values up to nearest integer.\n",
    "            return temp  # End loop on first run, only need one batch of values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCMSLIB00000001548 binned.txt\n",
      "109387080.0\n",
      "CCMSLIB00000001549 binned.txt\n",
      "32604272.0\n",
      "CCMSLIB00000001550 binned.txt\n",
      "43057184.0\n",
      "CCMSLIB00000001555 binned.txt\n",
      "367041.09\n",
      "CCMSLIB00000001563 binned.txt\n",
      "64301.03\n",
      "CCMSLIB00000001565 binned.txt\n",
      "9896.4\n",
      "CCMSLIB00000001566 binned.txt\n",
      "20734.69\n",
      "CCMSLIB00000001568 binned.txt\n",
      "333.72\n",
      "CCMSLIB00000001569 binned.txt\n",
      "103564.98\n",
      "CCMSLIB00000001570 binned.txt\n",
      "811.76\n",
      "CCMSLIB00000001572 binned.txt\n",
      "1546.8\n",
      "CCMSLIB00000001574 binned.txt\n",
      "5483.52\n",
      "CCMSLIB00000001576 binned.txt\n",
      "10734.39\n",
      "CCMSLIB00000001581 binned.txt\n",
      "19181776.0\n",
      "CCMSLIB00000001590 binned.txt\n",
      "172760.3\n",
      "CCMSLIB00000001598 binned.txt\n",
      "8115.84\n",
      "CCMSLIB00000001600 binned.txt\n",
      "26551.12\n",
      "CCMSLIB00000001601 binned.txt\n",
      "5995577.0\n",
      "CCMSLIB00000001602 binned.txt\n",
      "7592.63\n",
      "CCMSLIB00000001603 binned.txt\n",
      "111843406.0\n",
      "CCMSLIB00000001604 binned.txt\n",
      "35997.72\n",
      "CCMSLIB00000001606 binned.txt\n",
      "154432.59\n",
      "CCMSLIB00000001607 binned.txt\n",
      "317436.59\n",
      "CCMSLIB00000001608 binned.txt\n",
      "64228456.0\n",
      "CCMSLIB00000001609 binned.txt\n",
      "1634.13\n",
      "CCMSLIB00000001615 binned.txt\n",
      "486.43\n",
      "CCMSLIB00000001616 binned.txt\n",
      "3114.98\n",
      "CCMSLIB00000001617 binned.txt\n",
      "120044.4\n",
      "CCMSLIB00000001621 binned.txt\n",
      "186817.91\n",
      "CCMSLIB00000001622 binned.txt\n",
      "171162.91\n",
      "CCMSLIB00000001623 binned.txt\n",
      "696121.19\n",
      "CCMSLIB00000001624 binned.txt\n",
      "6232.86\n",
      "CCMSLIB00000001625 binned.txt\n",
      "640243.38\n",
      "CCMSLIB00000001631 binned.txt\n",
      "164380.8\n",
      "CCMSLIB00000001633 binned.txt\n",
      "135754.41\n",
      "CCMSLIB00000001634 binned.txt\n",
      "5480920.0\n",
      "CCMSLIB00000001635 binned.txt\n",
      "20470.89\n",
      "CCMSLIB00000001637 binned.txt\n",
      "12700.95\n",
      "CCMSLIB00000001638 binned.txt\n",
      "8752910.0\n",
      "CCMSLIB00000001641 binned.txt\n",
      "12845.37\n",
      "CCMSLIB00000001642 binned.txt\n",
      "5234278.0\n",
      "CCMSLIB00000001643 binned.txt\n",
      "8174.73\n",
      "CCMSLIB00000001645 binned.txt\n",
      "23540.32\n",
      "CCMSLIB00000001646 binned.txt\n",
      "9859244.0\n",
      "CCMSLIB00000001650 binned.txt\n",
      "74985897.0\n",
      "CCMSLIB00000001651 binned.txt\n",
      "637.88\n",
      "CCMSLIB00000001653 binned.txt\n",
      "1217.61\n",
      "CCMSLIB00000001655 binned.txt\n",
      "2021.29\n",
      "CCMSLIB00000001673 binned.txt\n",
      "4490.56\n",
      "CCMSLIB00000001676 binned.txt\n",
      "23910.69\n",
      "CCMSLIB00000001678 binned.txt\n",
      "8176.94\n",
      "CCMSLIB00000001680 binned.txt\n",
      "1827.32\n",
      "CCMSLIB00000001682 binned.txt\n",
      "2428.78\n",
      "CCMSLIB00000001702 binned.txt\n",
      "11213482.0\n",
      "CCMSLIB00000001707 binned.txt\n",
      "2292710.0\n",
      "CCMSLIB00000001711 binned.txt\n",
      "67812013.0\n",
      "CCMSLIB00000001712 binned.txt\n",
      "295991488.0\n",
      "CCMSLIB00000001715 binned.txt\n",
      "25125448.0\n",
      "CCMSLIB00000001729 binned.txt\n",
      "15342980.0\n",
      "CCMSLIB00000001730 binned.txt\n",
      "18534656.0\n",
      "CCMSLIB00000001754 binned.txt\n",
      "14596656.0\n",
      "CCMSLIB00000001756 binned.txt\n",
      "82638584.0\n",
      "CCMSLIB00000001757 binned.txt\n",
      "13099768.0\n",
      "CCMSLIB00000001759 binned.txt\n",
      "8247035.0\n",
      "CCMSLIB00000001760 binned.txt\n",
      "4282866.0\n",
      "CCMSLIB00000001761 binned.txt\n",
      "4948748.0\n",
      "CCMSLIB00000001776 binned.txt\n",
      "87530592.0\n",
      "CCMSLIB00000001777 binned.txt\n",
      "266457920.0\n",
      "CCMSLIB00000001778 binned.txt\n",
      "14096592.0\n",
      "CCMSLIB00000001784 binned.txt\n",
      "32900992.0\n",
      "CCMSLIB00000001785 binned.txt\n",
      "10124.0\n",
      "CCMSLIB00000001786 binned.txt\n",
      "35241328.0\n",
      "CCMSLIB00000001790 binned.txt\n",
      "507026.0\n",
      "CCMSLIB00000001791 binned.txt\n",
      "9111149.0\n",
      "CCMSLIB00000001798 binned.txt\n",
      "228700096.0\n",
      "CCMSLIB00000001799 binned.txt\n",
      "812085.0\n",
      "CCMSLIB00000001800 binned.txt\n",
      "3708640.0\n",
      "CCMSLIB00000001803 binned.txt\n",
      "12595312.0\n",
      "CCMSLIB00000001810 binned.txt\n",
      "191350.0\n",
      "CCMSLIB00000001811 binned.txt\n",
      "1825712.0\n",
      "CCMSLIB00000001812 binned.txt\n",
      "4024405.0\n",
      "CCMSLIB00000001813 binned.txt\n",
      "2228327.0\n",
      "CCMSLIB00000001814 binned.txt\n",
      "461813.0\n",
      "CCMSLIB00000004223 binned.txt\n",
      "78827.48\n",
      "CCMSLIB00000004235 binned.txt\n",
      "52726.29\n",
      "CCMSLIB00000004250 binned.txt\n",
      "26467.14\n",
      "CCMSLIB00000004253 binned.txt\n",
      "117740.28\n",
      "CCMSLIB00000004256 binned.txt\n",
      "18245.2\n",
      "CCMSLIB00000004259 binned.txt\n",
      "497447.86\n",
      "CCMSLIB00000004265 binned.txt\n",
      "1799763.86\n",
      "CCMSLIB00000004274 binned.txt\n",
      "280981.47\n",
      "CCMSLIB00000004277 binned.txt\n",
      "45939.07\n",
      "CCMSLIB00000004280 binned.txt\n",
      "3890.39\n",
      "CCMSLIB00000004283 binned.txt\n",
      "274932.91\n",
      "CCMSLIB00000004304 binned.txt\n",
      "59481.81\n",
      "CCMSLIB00000004307 binned.txt\n",
      "25851.16\n",
      "CCMSLIB00000004310 binned.txt\n",
      "1328.07\n",
      "CCMSLIB00000004313 binned.txt\n",
      "74550.79\n",
      "CCMSLIB00000004319 binned.txt\n",
      "2005.15\n",
      "CCMSLIB00000004322 binned.txt\n",
      "521.2\n",
      "Done\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(2995, 100)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "main = load_data()\n",
    "labels = load_bin_values()\n",
    "\n",
    "print(main)\n",
    "print(main.shape)\n",
    "print(main.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(2995, 100)\n",
      "float64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(main)\n",
    "print(main.shape)\n",
    "print(main.dtype)\n",
    "print(np.amax(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "(2995,)\n",
      "35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bins with only 0s: 1923\n",
      "Number of bins with 1 non-zero: 164\n",
      "Total number of bins with fewer than 6 non-zero values:2250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2992, 2993, 2994], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzeros = (np.count_nonzero(main, axis =1)) #Get count of non-zeros values for all bins.\n",
    "\n",
    "print(nonzeros)\n",
    "print(nonzeros.shape)\n",
    "print(np.amax(nonzeros)) #Highest number of non-zeros out of all bins.\n",
    "\n",
    "plt.plot(nonzeros, color = 'g')\n",
    "plt.axhline(y = 6, color = 'r')\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of bins with only 0s: \" + str(len(np.where(nonzeros==0)[0])))\n",
    "\n",
    "print(\"Number of bins with 1 non-zero: \" + str(len(np.where(nonzeros==1)[0])))\n",
    "\n",
    "print(\"Total number of bins with fewer than 6 non-zero values:\" + str(len(np.where(nonzeros<6)[0])))\n",
    "\n",
    "np.where(nonzeros<6)[0] #Indices of bins with <6 non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(745, 100)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "testmain = main #Keep copy of untrimmed matrix, just in case.\n",
    "testmain = np.delete(testmain, np.where(nonzeros<6)[0], axis = 0) #Remove features that have <6 non-zeros values.\n",
    "print(testmain.shape)\n",
    "\n",
    "nzero = (np.count_nonzero(testmain, axis =1))\n",
    "print(len(np.where(nzero<6)[0])) #Verify that all <6 non-zero features were removed. Should output 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43484072 0.02695135 0.04261613 0.29273038 0.03257983 0.25858189\n",
      " 0.03723521 0.14883651 0.56879093 0.05509067]\n",
      "(745,)\n",
      "145\n",
      "(600, 100)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "maxVals = np.amax(testmain, axis=1) #Get max values for each feature.\n",
    "print(maxVals[:10])\n",
    "print(maxVals.shape)\n",
    "print(len(np.where(maxVals<0.05)[0])) #Output number of bins with max value <0.05.\n",
    "testmain = np.delete(testmain, np.where(maxVals<0.05)[0], axis=0) #Remove features that have max value <0.05\n",
    "print(testmain.shape)\n",
    "numFeatures = testmain.shape[0] #Update feature number variable\n",
    "\n",
    "maxValsVerify = (np.amax(testmain, axis = 1))\n",
    "print(len(np.where(maxValsVerify<0.05)[0])) #Verify said features have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 100)\n"
     ]
    }
   ],
   "source": [
    "print(testmain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_autoencoder(data):\n",
    "    x_train = data\n",
    "    # x_train = x_train.reshape((1, -1))\n",
    "    x_train = x_train.transpose()  # transpose so that axis 0 is samples.\n",
    "    print(x_train.shape)\n",
    "    print(x_train[0].shape)\n",
    "\n",
    "    # inputLayer = Input(shape=x_train.shape) #This line brings up this error: expected input_4 to have 3 dimensions, but got array with shape (600, 100)\n",
    "    inputLayer = Input(shape=(x_train.shape[1],))  # fixed\n",
    "\n",
    "    l = inputLayer\n",
    "    l = Dense(256, activation='relu')(l)\n",
    "    l = Dense(128, activation='relu')(l)\n",
    "    l = Dense(16, activation='relu')(l)\n",
    "    l = Dense(8)(l)\n",
    "\n",
    "    latent_space = l\n",
    "\n",
    "    l2 = Dense(16, activation='relu')(l)\n",
    "    l2 = Dense(128, activation='relu')(l2)\n",
    "    l2 = Dense(256, activation='relu')(l2)\n",
    "    l2 = Dense(600, activation='linear')(l2)\n",
    "\n",
    "    out_layer = l2\n",
    "\n",
    "    auto_model = Model(input=inputLayer, outputs=out_layer)\n",
    "\n",
    "    auto_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    # Fixed this line: added x_train again: you need to give it the targets! Also removed the batch stuff\n",
    "    auto_model.fit(x_train, x_train, shuffle=False, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 600)\n",
      "(600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matej\\envs\\masters\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.0028\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 330us/step - loss: 0.0028\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.0028\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.0028\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.0028\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.0028\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.0028\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.0028\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 210us/step - loss: 0.0028\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.0028\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.0028\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.0028\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.0028\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.0028\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 210us/step - loss: 0.0028\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0028\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0028\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.0028\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.0028\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0028\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0028\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.0028\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 250us/step - loss: 0.0028\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.0028\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.0028\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0028\n"
     ]
    }
   ],
   "source": [
    "basic_autoencoder(testmain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
